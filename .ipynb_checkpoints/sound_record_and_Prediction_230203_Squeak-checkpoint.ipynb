{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c375e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활용(240503)\n",
    "\n",
    "import sounddevice\n",
    "#from scipy.io.wavfile import write\n",
    "\n",
    "#def voice_recorder(seconds, file):\n",
    "def voice_recorder(seconds):\n",
    "    print(\"Recording Started…\")\n",
    "    recording = sounddevice.rec((seconds * 44100), samplerate= 44100, channels=1)   # 44100/2=22050\n",
    "    sounddevice.wait()\n",
    "    #write(file, 44100, recording)\n",
    "    \n",
    "    return recording\n",
    "\n",
    "    print(\"Recording Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d27e35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording Started…\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.05175781e-05 ... -6.10351562e-05\n",
      "  -9.15527344e-05 -3.05175781e-05]]\n",
      "Recording Started…\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.05175781e-05 ...  0.00000000e+00\n",
      "  -3.05175781e-05 -3.05175781e-05]]\n",
      "Recording Started…\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.05175781e-05 ...  9.15527344e-05\n",
      "   6.10351562e-05  9.15527344e-05]]\n",
      "Recording Started…\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.05175781e-05 ... -3.05175781e-05\n",
      "  -6.10351562e-05  0.00000000e+00]]\n",
      "Recording Started…\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.05175781e-05 ...  0.00000000e+00\n",
      "  -3.05175781e-05  3.05175781e-05]]\n",
      "Recording Started…\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.05175781e-05 ...  3.05175781e-05\n",
      "   0.00000000e+00  3.05175781e-05]]\n",
      "Recording Started…\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.05175781e-05 ... -3.05175781e-05\n",
      "  -9.15527344e-05 -6.10351562e-05]]\n",
      "Recording Started…\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.05175781e-05 ... -1.52587891e-04\n",
      "  -2.13623047e-04 -1.83105469e-04]]\n",
      "Recording Started…\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.05175781e-05 ...  3.05175781e-05\n",
      "  -3.05175781e-05  0.00000000e+00]]\n",
      "Recording Started…\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.05175781e-05 ...  3.05175781e-05\n",
      "   0.00000000e+00  3.05175781e-05]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "frame_size = 1.0\n",
    "sr = 44100\n",
    "n_frame = 10\n",
    "\n",
    "rec_frame_vectors = np.zeros((10, 44100))\n",
    "\n",
    "for i in range(n_frame):\n",
    "    rec_frame_vectors[i] = voice_recorder(1).reshape(1, -1)\n",
    "    print(rec_frame_vectors[i].reshape(1, -1))\n",
    "    \n",
    "    # 여기에 모델을 불러와서 결과를 출력하는 코드 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9996df44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 44100)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_frame_vectors.shape   # 1초씩 10개의 녹음 데이터가 실시간으로 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f61eea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=(6, 4), stride=2, padding=0),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=(4, 6), stride=2, padding=0),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # 전결합층 ?x?x64 inputs -> 1 outputs\n",
    "        self.fc1 = torch.nn.Linear(1792, 16, bias=True)       \n",
    "        self.fc2 = torch.nn.Linear(16, 1, bias=True)       \n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()     # 출력이 0 or 1이 되도록 이진 분류\n",
    "        \n",
    "        # 전결합층 한정으로 가중치 초기\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)        \n",
    "        torch.nn.init.zeros_(self.fc1.bias)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)        \n",
    "        torch.nn.init.zeros_(self.fc2.bias)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
    "        out = self.fc1(out)        \n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        #out = torch.round(out)    # 텐서 반올림 방법 -> 0 또는 1만 출력\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "39fa6239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(6, 4), stride=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(4, 6), stride=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1792, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = CNN()    \n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7207800f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(6, 4), stride=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(4, 6), stride=(2, 2))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=1792, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 로딩하는 방법 \n",
    "\n",
    "\n",
    "# 모델 구조를 미리 선언하고 로딩할 것 (230203)\n",
    "# model = torch.load(\"model_bird.pth\")   # 에러 발생\n",
    "# print(model)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"model_squeak.pth\"))\n",
    "model.eval()    \n",
    "\n",
    "# 여기에 굳이 작성하지 않아도 동작에 문제 없지 않은가? (230324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aa840e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nmodel.train()\\n: 학습할 때와 추론할 때 다르게 동작하는 Layer들을 Training mode로 변환\\n\\nmodel.eval() \\n: 학습할 때와 추론할 때 다르게 동작하는 Layer들을 Evaluation(Inference) mode로 변환\\n: model.eval()과 model.train(False)는 동일한 기능을 한다.\\n\\ntorch.no_grad()\\n: Autograd Engine을 비활성화하여 Gradient를 계산하지 않도록 한다.\\n: 메모리 사용량을 줄이고 계산 속도를 빠르게 만든다.\\n: 데코레이터로(@)로 사용할 수 있기 때문에 Gradient 계산이 필요없는 연산을 수행하는 \\n함수를 사전에 지정할 수도 있다.\\n\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://tigris-data-science.tistory.com/entry/PyTorch-modeltrain-vs-modeleval-vs-torchnograd\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "model.train()\n",
    ": 학습할 때와 추론할 때 다르게 동작하는 Layer들을 Training mode로 변환\n",
    "\n",
    "model.eval() \n",
    ": 학습할 때와 추론할 때 다르게 동작하는 Layer들을 Evaluation(Inference) mode로 변환\n",
    ": model.eval()과 model.train(False)는 동일한 기능을 한다.\n",
    "\n",
    "torch.no_grad()\n",
    ": Autograd Engine을 비활성화하여 Gradient를 계산하지 않도록 한다.\n",
    ": 메모리 사용량을 줄이고 계산 속도를 빠르게 만든다.\n",
    ": 데코레이터로(@)로 사용할 수 있기 때문에 Gradient 계산이 필요없는 연산을 수행하는 \n",
    "함수를 사전에 지정할 수도 있다.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d818b6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording Started…\n",
      "Squeak Noise Detected!\n",
      "Recording Started…\n",
      "Squeak Noise Detected!\n",
      "Recording Started…\n",
      "Squeak Noise Detected!\n",
      "Recording Started…\n",
      "No Noise!\n",
      "Recording Started…\n",
      "Squeak Noise Detected!\n",
      "Recording Started…\n",
      "Squeak Noise Detected!\n",
      "Recording Started…\n",
      "Squeak Noise Detected!\n",
      "Recording Started…\n",
      "No Noise!\n",
      "Recording Started…\n",
      "No Noise!\n",
      "Recording Started…\n",
      "Squeak Noise Detected!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "frame_size = 1.0\n",
    "sr = 44100 #22050           # Sampling Rate 일치 시키기 -> 행렬 곱셈 진행 가능하도록\n",
    "n_frame = 10\n",
    "\n",
    "for i in range(n_frame):\n",
    "    rec_frame_vectors = voice_recorder(1).reshape(1, -1)\n",
    "    #print(rec_frame_vectors.reshape(1, -1))\n",
    "    \n",
    "    Spectrum_vector = librosa.feature.melspectrogram(y=rec_frame_vectors, sr=sr)\n",
    "    Spectrum_vector = librosa.power_to_db(Spectrum_vector, ref=np.max)   # 특성 변경을 위해 추가(230203)\n",
    "    \n",
    "    #print(Spectrum_vector)\n",
    "    #print(Spectrum_vector.shape)\n",
    "    \n",
    "    # 여기에 모델을 불러와서 실시간 녹음 결과를 검토하는 코드 추가\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        model.eval()\n",
    "        inputs = torch.FloatTensor([Spectrum_vector])    # 대괄호 추가 -> 매트릭스 형태 (1, 1, 128, 44) (230203)\n",
    "        outputs = model(inputs) \n",
    "        \n",
    "        #print(outputs.numpy()[0][0]) \n",
    "        \n",
    "        if round(outputs.numpy()[0][0]) == 0:    # 기본 상태에서 계속 0을 출력 ---> 노트북 내부의 잡음 문제로 판단 (230203)\n",
    "            print(\"Squeak Noise Detected!\") \n",
    "            \n",
    "        if round(outputs.numpy()[0][0]) == 1:\n",
    "            print(\"No Noise!\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab412d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a72734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
